# If you intened to deploy Kubernetes in an air-gapped environment,
# please consult the documentation on how to configure custom RKE images.
nodes:
- address: 10.72.1.114
  port: "22"
  internal_address: ""
  role:
  - controlplane
  - etcd
  hostname_override: "ip-10-72-1-114.ap-northeast-1.compute.internal"
  user: rancher
  docker_socket: /var/run/docker.sock
  ssh_key: ""
  ssh_key_path: ~/.ssh/id_rsa
  ssh_cert: ""
  ssh_cert_path: ""
  labels: {}
- address: 10.72.1.163
  port: "22"
  internal_address: ""
  role:
  - worker
  hostname_override: "ip-10-72-1-163.ap-northeast-1.compute.internal"
  user: rancher
  docker_socket: /var/run/docker.sock
  ssh_key: ""
  ssh_key_path: ~/.ssh/id_rsa
  ssh_cert: ""
  ssh_cert_path: ""
  labels: {}
- address: 10.72.1.206
  port: "22"
  internal_address: ""
  role:
  - worker
  hostname_override: "ip-10-72-1-206.ap-northeast-1.compute.internal"
  user: rancher
  docker_socket: /var/run/docker.sock
  ssh_key: ""
  ssh_key_path: ~/.ssh/id_rsa
  ssh_cert: ""
  ssh_cert_path: ""
  labels: {}
- address: 10.72.1.208
  port: "22"
  internal_address: ""
  role:
  - worker
  hostname_override: "ip-10-72-1-208.ap-northeast-1.compute.internal"
  user: rancher
  docker_socket: /var/run/docker.sock
  ssh_key: ""
  ssh_key_path: ~/.ssh/id_rsa
  ssh_cert: ""
  ssh_cert_path: ""
  labels: {}
services:
  etcd:
    image: ""
    extra_args: {}
    extra_binds: []
    extra_env: []
    external_urls: []
    ca_cert: ""
    cert: ""
    key: ""
    path: ""
    snapshot: null
    retention: ""
    creation: ""
    backup_config: null
  kube-api:
    image: ""
    extra_args: {}
    extra_binds: []
    extra_env: []
    service_cluster_ip_range: 10.96.0.0/12
    service_node_port_range: ""
    pod_security_policy: false
    always_pull_images: false
  kube-controller:
    image: ""
    extra_args: {}
    extra_binds: []
    extra_env: []
    cluster_cidr: 10.32.0.0/16
    service_cluster_ip_range: 10.96.0.0/12
  scheduler:
    image: ""
    extra_args: {}
    extra_binds: []
    extra_env: []
  kubelet:
    image: ""
    extra_args: {}
    extra_binds: []
    extra_env: []
    cluster_domain: cluster.local
    infra_container_image: ""
    cluster_dns_server: 10.96.0.10
    fail_swap_on: false
  kubeproxy:
    image: ""
    extra_args: {}
    extra_binds: []
    extra_env: []
network:
  plugin: weave
  options: {}
authentication:
  strategy: x509
  sans: []
  webhook: null
addons: |-
  ---
  apiVersion: v1
  kind: Secret
  metadata:
    name: ingress-default-cert
    namespace: ingress-nginx
  type: kubernetes.io/tls
  data:
    tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURHekNDQWdPZ0F3SUJBZ0lKQUpXK2dodGpubThMTUEwR0NTcUdTSWIzRFFFQkN3VUFNQ1F4RURBT0JnTlYKQkFNTUIyMW1hUzFyT0hNeEVEQU9CZ05WQkFvTUIyMW1hUzFyT0hNd0hoY05NakF3TkRFd01EY3dPVFV3V2hjTgpNakV3TkRFd01EY3dPVFV3V2pBa01SQXdEZ1lEVlFRRERBZHRabWt0YXpoek1SQXdEZ1lEVlFRS0RBZHRabWt0CmF6aHpNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXV5ZHBrd0FQK3JGd1pTbUQKMHZ0SHJrT2FHd1AzNktMdldiY09WRWZpYXNiRjNRRWwrcktjTm5UZDBoazl2cVh6L0ZNelhoZ1dVZk1mQU5EUgo0NGR2NlVvRUovQzRNVmV0eExIOWVDczFsT1c2Qmx5NkhidStueEZ0UVo2TmZzWmJ2eUIxM1RDeHAzMmlWM2IwCnFDNmZWMStya09wa1lNdmp2dXc2MW5LWlBrdmU3OGZkdTlsdHdjUndzNVRSTEVBWDhFUDlvM2o4Wm5iU3ptcSsKUjJGNmpMV3RRaHkxT3lmL3pUYzUydlI1VUpINnh6VVhMcFpQaTZrS0FubWtSQWdNWDJiMitDWmlmQWFJeDJ5SgphYXZMb3VRV0tDUEV3UXh5ZjE3YStFcGcvYUhMVGt4cTRaTWNxQ2szWlIrc21TNmhZOGI0anRVUDIydU9USXZUClVFUzNtUUlEQVFBQm8xQXdUakFkQmdOVkhRNEVGZ1FVUjZBWGdyV0Z6ZHpQc3ZmWDVubGpBZk1tSXFvd0h3WUQKVlIwakJCZ3dGb0FVUjZBWGdyV0Z6ZHpQc3ZmWDVubGpBZk1tSXFvd0RBWURWUjBUQkFVd0F3RUIvekFOQmdrcQpoa2lHOXcwQkFRc0ZBQU9DQVFFQVBucjJVdTN4V2RUSDlINEgvV0NvTFdMV0FaWE9OeHZrTDBENnlLVHoyTXhiCndNYWxIRDlaa2d6U2I0K0wwSlY5SmxLcEovYXdGRkNUU1BNM3FZdXhVRC92RFBWbzFoQ0pBazRicnpmV0Zjc3AKVjF2cGttRnJuc0VkWWE1Y1hsV0NrTkRaTjRWdzF0bHhnWUE0bUVUMlBXcVBvMzcrbVJDZUtxaU13bVREU3RMcwpaNS9TUUMrMlNxT1A2TndIL2pDSHBZOXNLc3dkTVphRGtOVlFRUU1TL1k0bjBudVlWUStjcmJScEo5dzRiTGRjCmFVWjRCZnBxbE5FakxScHRNb3lmQTAycEZvNHRsMXp4Q1U5Y2dzWFFyRjl6bWNjb1hZU2N4ejBrNzJXRGhYcmUKbjAxNmg3L1VFdksyQ0szL01Oa0U4SWhXZUQ4ZVVmQ3NCdmNvNGFQamhRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    tls.key: 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
  ---
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: ceph-csi-config
  data:
    config.json: |-
      [
        {
          "clusterID": "34a878d5-6aaf-4ad6-82ab-71df2b5989a8",
          "monitors": [
            "10.72.4.45:6789"
          ]
        }
      ]
  ---
  apiVersion: v1
  kind: Secret
  metadata:
    name: csi-rbd-secret
  stringData:
    userID: kube
    userKey: AQBl8IJesAKuOBAAsZlVJoMhJwoDUD6NIe9CeQ==
  ---
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: rbd-csi-provisioner
  ---
  kind: ClusterRole
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: rbd-external-provisioner-runner
  aggregationRule:
    clusterRoleSelectors:
      - matchLabels:
          rbac.rbd.csi.ceph.com/aggregate-to-rbd-external-provisioner-runner: "true"
  rules: []
  ---
  kind: ClusterRole
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: rbd-external-provisioner-runner-rules
    labels:
      rbac.rbd.csi.ceph.com/aggregate-to-rbd-external-provisioner-runner: "true"
  rules:
    - apiGroups: [""]
      resources: ["secrets"]
      verbs: ["get", "list"]
    - apiGroups: [""]
      resources: ["events"]
      verbs: ["list", "watch", "create", "update", "patch"]
    - apiGroups: [""]
      resources: ["persistentvolumes"]
      verbs: ["get", "list", "watch", "create", "update", "delete", "patch"]
    - apiGroups: [""]
      resources: ["persistentvolumeclaims"]
      verbs: ["get", "list", "watch", "update"]
    - apiGroups: ["storage.k8s.io"]
      resources: ["storageclasses"]
      verbs: ["get", "list", "watch"]
    - apiGroups: ["snapshot.storage.k8s.io"]
      resources: ["volumesnapshots"]
      verbs: ["get", "list", "watch", "update"]
    - apiGroups: ["snapshot.storage.k8s.io"]
      resources: ["volumesnapshotcontents"]
      verbs: ["create", "get", "list", "watch", "update", "delete"]
    - apiGroups: ["snapshot.storage.k8s.io"]
      resources: ["volumesnapshotclasses"]
      verbs: ["get", "list", "watch"]
    - apiGroups: ["apiextensions.k8s.io"]
      resources: ["customresourcedefinitions"]
      verbs: ["create", "list", "watch", "delete", "get", "update"]
    - apiGroups: ["storage.k8s.io"]
      resources: ["volumeattachments"]
      verbs: ["get", "list", "watch", "update", "patch"]
    - apiGroups: ["snapshot.storage.k8s.io"]
      resources: ["volumesnapshots/status"]
      verbs: ["update"]
    - apiGroups: [""]
      resources: ["persistentvolumeclaims/status"]
      verbs: ["update", "patch"]
  ---
  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: rbd-csi-provisioner-role
  subjects:
    - kind: ServiceAccount
      name: rbd-csi-provisioner
      namespace: kube-system
  roleRef:
    kind: ClusterRole
    name: rbd-external-provisioner-runner
    apiGroup: rbac.authorization.k8s.io
  ---
  kind: Role
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
  # replace with non-default namespace name
    namespace: kube-system
    name: rbd-external-provisioner-cfg
  rules:
    - apiGroups: [""]
      resources: ["configmaps"]
      verbs: ["get", "list", "watch", "create", "delete"]
    - apiGroups: ["coordination.k8s.io"]
      resources: ["leases"]
      verbs: ["get", "watch", "list", "delete", "update", "create"]
  ---
  kind: RoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: rbd-csi-provisioner-role-cfg
    # replace with non-default namespace name
    namespace: kube-system
  subjects:
    - kind: ServiceAccount
      name: rbd-csi-provisioner
      # replace with non-default namespace name
      namespace: kube-system
  roleRef:
    kind: Role
    name: rbd-external-provisioner-cfg
    apiGroup: rbac.authorization.k8s.io
  ---
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: rbd-csi-nodeplugin
  ---
  kind: Service
  apiVersion: v1
  metadata:
    name: csi-rbdplugin-provisioner
    labels:
      app: csi-metrics
  spec:
    selector:
      app: csi-rbdplugin-provisioner
    ports:
      - name: http-metrics
        port: 8080
        protocol: TCP
        targetPort: 8680
  ---
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: ceph-csi-encryption-kms-config
  data:
    config.json: |-
      {
        "vault-test": {
           "encryptionKMSType": "vault",
           "vaultAddress": "http://vault.default.svc.cluster.local:8200",
           "vaultAuthPath": "/v1/auth/kubernetes/login",
           "vaultRole": "csi-kubernetes",
           "vaultPassphraseRoot": "/v1/secret",
           "vaultPassphrasePath": "ceph-csi/",
           "vaultCAVerify": "false"
         }
      }
  ---
  kind: Deployment
  apiVersion: apps/v1
  metadata:
    name: csi-rbdplugin-provisioner
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: csi-rbdplugin-provisioner
    template:
      metadata:
        labels:
          app: csi-rbdplugin-provisioner
      spec:
        serviceAccount: rbd-csi-provisioner
        containers:
          - name: csi-provisioner
            image: registry.hitachiapps.com:5000/csi-provisioner:v1.4.0
            args:
              - "--csi-address=$(ADDRESS)"
              - "--v=5"
              - "--timeout=150s"
              - "--retry-interval-start=500ms"
              - "--enable-leader-election=true"
              - "--leader-election-type=leases"
            env:
              - name: ADDRESS
                value: unix:///csi/csi-provisioner.sock
            imagePullPolicy: "IfNotPresent"
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
          - name: csi-snapshotter
            image: registry.hitachiapps.com:5000/csi-snapshotter:v1.2.2
            args:
              - "--csi-address=$(ADDRESS)"
              - "--v=5"
              - "--timeout=150s"
              - "--leader-election=true"
            env:
              - name: ADDRESS
                value: unix:///csi/csi-provisioner.sock
            imagePullPolicy: Always
            securityContext:
              privileged: true
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
          - name: csi-attacher
            image: registry.hitachiapps.com:5000/csi-attacher:v2.1.1
            args:
              - "--v=5"
              - "--csi-address=$(ADDRESS)"
              - "--leader-election=true"
            env:
              - name: ADDRESS
                value: /csi/csi-provisioner.sock
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
            imagePullPolicy: "IfNotPresent"
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
          - name: csi-resizer
            image: registry.hitachiapps.com:5000/csi-resizer:v0.5.0
            args:
              - "--csi-address=$(ADDRESS)"
              - "--v=5"
              - "--csiTimeout=150s"
              - "--leader-election"
            env:
              - name: ADDRESS
                value: unix:///csi/csi-provisioner.sock
            imagePullPolicy: "IfNotPresent"
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
          - name: csi-rbdplugin
            securityContext:
              privileged: true
              capabilities:
                add: ["SYS_ADMIN"]
          # for stable functionality replace canary with latest release version
            image:  registry.hitachiapps.com:5000/cephcsi:v2.1.1
            args:
              - "--nodeid=$(NODE_ID)"
              - "--type=rbd"
              - "--controllerserver=true"
              - "--endpoint=$(CSI_ENDPOINT)"
              - "--v=5"
              - "--drivername=rbd.csi.ceph.com"
              - "--pidlimit=-1"
            env:
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: NODE_ID
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
              - name: CSI_ENDPOINT
                value: unix:///csi/csi-provisioner.sock
            imagePullPolicy: "IfNotPresent"
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
              - mountPath: /dev
                name: host-dev
              - mountPath: /sys
                name: host-sys
              - mountPath: /lib/modules
                name: lib-modules
                readOnly: true
              - name: ceph-csi-config
                mountPath: /etc/ceph-csi-config/
              - name: ceph-csi-encryption-kms-config
                mountPath: /etc/ceph-csi-encryption-kms-config/
              - name: keys-tmp-dir
                mountPath: /tmp/csi/keys
          - name: liveness-prometheus
            image: registry.hitachiapps.com:5000/cephcsi:v2.1.1
            args:
              - "--type=liveness"
              - "--endpoint=$(CSI_ENDPOINT)"
              - "--metricsport=8680"
              - "--metricspath=/metrics"
              - "--polltime=60s"
              - "--timeout=3s"
            env:
              - name: CSI_ENDPOINT
                value: unix:///csi/csi-provisioner.sock
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
            imagePullPolicy: "IfNotPresent"
        volumes:
          - name: host-dev
            hostPath:
              path: /dev
          - name: host-sys
            hostPath:
              path: /sys
          - name: lib-modules
            hostPath:
              path: /lib/modules
          - name: socket-dir
            emptyDir: {
              medium: "Memory"
            }
          - name: ceph-csi-config
            configMap:
              name: ceph-csi-config
          - name: ceph-csi-encryption-kms-config
            configMap:
              name: ceph-csi-encryption-kms-config
          - name: keys-tmp-dir
            emptyDir: {
              medium: "Memory"
            }
  ---
  kind: DaemonSet
  apiVersion: apps/v1
  metadata:
    name: csi-rbdplugin
  spec:
    selector:
      matchLabels:
        app: csi-rbdplugin
    template:
      metadata:
        labels:
          app: csi-rbdplugin
      spec:
        serviceAccount: rbd-csi-nodeplugin
        hostNetwork: true
        hostPID: true
        # to use e.g. Rook orchestrated cluster, and mons' FQDN is
        # resolved through k8s service, set dns policy to cluster first
        dnsPolicy: ClusterFirstWithHostNet
        containers:
          - name: driver-registrar
            # This is necessary only for systems with SELinux, where
            # non-privileged sidecar containers cannot access unix domain socket
            # created by privileged CSI driver container.
            securityContext:
              privileged: true
            image: registry.hitachiapps.com:5000/csi-node-driver-registrar:v1.3.0
            args:
              - "--v=5"
              - "--csi-address=/csi/csi.sock"
              - "--kubelet-registration-path=/var/lib/kubelet/plugins/rbd.csi.ceph.com/csi.sock"
            lifecycle:
              preStop:
                exec:
                  command: [
                    "/bin/sh", "-c",
                    "rm -rf /registration/rbd.csi.ceph.com \
                    /registration/rbd.csi.ceph.com-reg.sock"
                  ]
            env:
              - name: KUBE_NODE_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
              - name: registration-dir
                mountPath: /registration
          - name: csi-rbdplugin
            securityContext:
              privileged: true
              capabilities:
                add: ["SYS_ADMIN"]
              allowPrivilegeEscalation: true
            # for stable functionality replace canary with latest release version
            image: registry.hitachiapps.com:5000/cephcsi:v2.1.1
            args:
              - "--nodeid=$(NODE_ID)"
              - "--type=rbd"
              - "--nodeserver=true"
              - "--endpoint=$(CSI_ENDPOINT)"
              - "--v=5"
              - "--drivername=rbd.csi.ceph.com"
            env:
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: NODE_ID
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: CSI_ENDPOINT
                value: unix:///csi/csi.sock
            imagePullPolicy: "IfNotPresent"
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
              - mountPath: /dev
                name: host-dev
              - mountPath: /sys
                name: host-sys
              - mountPath: /run/mount
                name: host-mount
              - mountPath: /lib/modules
                name: lib-modules
                readOnly: true
              - name: ceph-csi-config
                mountPath: /etc/ceph-csi-config/
              - name: ceph-csi-encryption-kms-config
                mountPath: /etc/ceph-csi-encryption-kms-config/
              - name: plugin-dir
                mountPath: /var/lib/kubelet/plugins
                mountPropagation: "Bidirectional"
              - name: mountpoint-dir
                mountPath: /var/lib/kubelet/pods
                mountPropagation: "Bidirectional"
              - name: keys-tmp-dir
                mountPath: /tmp/csi/keys
          - name: liveness-prometheus
            securityContext:
              privileged: true
            image: registry.hitachiapps.com:5000/cephcsi:v2.1.1
            args:
              - "--type=liveness"
              - "--endpoint=$(CSI_ENDPOINT)"
              - "--metricsport=8680"
              - "--metricspath=/metrics"
              - "--polltime=60s"
              - "--timeout=3s"
            env:
              - name: CSI_ENDPOINT
                value: unix:///csi/csi.sock
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
            volumeMounts:
              - name: socket-dir
                mountPath: /csi
            imagePullPolicy: "IfNotPresent"
        volumes:
          - name: socket-dir
            hostPath:
              path: /var/lib/kubelet/plugins/rbd.csi.ceph.com
              type: DirectoryOrCreate
          - name: plugin-dir
            hostPath:
              path: /var/lib/kubelet/plugins
              type: Directory
          - name: mountpoint-dir
            hostPath:
              path: /var/lib/kubelet/pods
              type: DirectoryOrCreate
          - name: registration-dir
            hostPath:
              path: /var/lib/kubelet/plugins_registry/
              type: Directory
          - name: host-dev
            hostPath:
              path: /dev
          - name: host-sys
            hostPath:
              path: /sys
          - name: host-mount
            hostPath:
              path: /run/mount
          - name: lib-modules
            hostPath:
              path: /lib/modules
          - name: ceph-csi-config
            configMap:
              name: ceph-csi-config
          - name: ceph-csi-encryption-kms-config
            configMap:
              name: ceph-csi-encryption-kms-config
          - name: keys-tmp-dir
            emptyDir: {
              medium: "Memory"
            }
  ---
  # This is a service to expose the liveness metrics
  apiVersion: v1
  kind: Service
  metadata:
    name: csi-metrics-rbdplugin
    labels:
      app: csi-metrics
  spec:
    ports:
      - name: http-metrics
        port: 8080
        protocol: TCP
        targetPort: 8680
    selector:
      app: csi-rbdplugin
  ---
  apiVersion: storage.k8s.io/v1
  kind: StorageClass
  metadata:
     name: csi-rbd-sc
  provisioner: rbd.csi.ceph.com
  parameters:
     clusterID: 34a878d5-6aaf-4ad6-82ab-71df2b5989a8
     pool: kube
     csi.storage.k8s.io/provisioner-secret-name: csi-rbd-secret
     csi.storage.k8s.io/provisioner-secret-namespace: kube-system
     csi.storage.k8s.io/node-stage-secret-name: csi-rbd-secret
     csi.storage.k8s.io/node-stage-secret-namespace: kube-system
  reclaimPolicy: Delete
  mountOptions:
     - discard
  ---
  # The following code is for cephfs provisioner and StorageClass
  apiVersion: v1
  kind: Secret
  metadata:
    name: ceph-secret-admin
    namespace: kube-system
  stringData:
    key: AQAq9LheiPwnOBAAXS8nBopbAohwFwBQLg2X9w==
  ---
  kind: ClusterRole
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: cephfs-provisioner
    namespace: kube-system
  rules:
    - apiGroups: [""]
      resources: ["persistentvolumes"]
      verbs: ["get", "list", "watch", "create", "delete"]
    - apiGroups: [""]
      resources: ["persistentvolumeclaims"]
      verbs: ["get", "list", "watch", "update"]
    - apiGroups: ["storage.k8s.io"]
      resources: ["storageclasses"]
      verbs: ["get", "list", "watch"]
    - apiGroups: [""]
      resources: ["events"]
      verbs: ["create", "update", "patch"]
    - apiGroups: [""]
      resources: ["services"]
      resourceNames: ["kube-dns","coredns"]
      verbs: ["list", "get"]
  ---
  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: cephfs-provisioner
  subjects:
    - kind: ServiceAccount
      name: cephfs-provisioner
      namespace: kube-system
  roleRef:
    kind: ClusterRole
    name: cephfs-provisioner
    apiGroup: rbac.authorization.k8s.io
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    name: cephfs-provisioner
    namespace: kube-system
  rules:
    - apiGroups: [""]
      resources: ["secrets"]
      verbs: ["create", "get", "delete"]
    - apiGroups: [""]
      resources: ["endpoints"]
      verbs: ["get", "list", "watch", "create", "update", "patch"]
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    name: cephfs-provisioner
    namespace: kube-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: cephfs-provisioner
  subjects:
  - kind: ServiceAccount
    name: cephfs-provisioner
  ---
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: cephfs-provisioner
    namespace: kube-system
  ---
  kind: StorageClass
  apiVersion: storage.k8s.io/v1
  metadata:
    name: cephfs
  provisioner: ceph.com/cephfs
  parameters:
    monitors: 10.72.4.45:6789
    adminId: admin
    adminSecretName: ceph-secret-admin
    adminSecretNamespace: kube-system
    claimRoot: /pvc-volumes
  ---
  apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: cephfs-provisioner
    namespace: kube-system
  spec:
    replicas: 1
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          app: cephfs-provisioner
      spec:
        serviceAccount: cephfs-provisioner
        containers:
        - name: cephfs-provisioner
          image: "quay.io/external_storage/cephfs-provisioner:v2.1.0-k8s1.11"
          env:
          - name: PROVISIONER_NAME
            value: ceph.com/cephfs
          - name: PROVISIONER_SECRET_NAMESPACE
            value: kube-system
          command:
          - "/usr/local/bin/cephfs-provisioner"
          args:
          - "-id=cephfs-provisioner-1"
  ---
addons_include: []
system_images:
  etcd: rancher/coreos-etcd:v3.4.3-rancher1
  alpine: rancher/rke-tools:v0.1.72
  nginx_proxy: rancher/rke-tools:v0.1.72
  cert_downloader: rancher/rke-tools:v0.1.72
  kubernetes_services_sidecar: rancher/rke-tools:v0.1.72
  kubedns: rancher/k8s-dns-kube-dns:1.15.2
  dnsmasq: rancher/k8s-dns-dnsmasq-nanny:1.15.2
  kubedns_sidecar: rancher/k8s-dns-sidecar:1.15.2
  kubedns_autoscaler: rancher/cluster-proportional-autoscaler:1.7.1
  coredns: rancher/coredns-coredns:1.6.9
  coredns_autoscaler: rancher/cluster-proportional-autoscaler:1.7.1
  nodelocal: rancher/k8s-dns-node-cache:1.15.7
  kubernetes: rancher/hyperkube:v1.18.16-rancher1
  flannel: rancher/coreos-flannel:v0.12.0
  flannel_cni: rancher/flannel-cni:v0.3.0-rancher6
  calico_node: rancher/calico-node:v3.13.4
  calico_cni: rancher/calico-cni:v3.13.4
  calico_controllers: rancher/calico-kube-controllers:v3.13.4
  calico_ctl: rancher/calico-ctl:v3.13.4
  calico_flexvol: rancher/calico-pod2daemon-flexvol:v3.13.4
  canal_node: rancher/calico-node:v3.13.4
  canal_cni: rancher/calico-cni:v3.13.4
  canal_flannel: rancher/coreos-flannel:v0.12.0
  canal_flexvol: rancher/calico-pod2daemon-flexvol:v3.13.4
  weave_node: weaveworks/weave-kube:2.6.4
  weave_cni: weaveworks/weave-npc:2.6.4
  pod_infra_container: rancher/pause:3.1
  ingress: rancher/nginx-ingress-controller:nginx-0.35.0-rancher2
  ingress_backend: rancher/nginx-ingress-controller-defaultbackend:1.5-rancher1
  metrics_server: rancher/metrics-server:v0.3.6
ssh_key_path: ~/.ssh/id_rsa
ssh_cert_path: ""
ssh_agent_auth: false
authorization:
  mode: rbac
  options: {}
ignore_docker_version: false
kubernetes_version: ""
private_registries: []
ingress:
  provider: "nginx"
  options:
    proxy-buffer-size: 16k
    proxy-buffering: 'off'
    proxy-buffers: 64 4k
    proxy-busy-buffers-size: 24k
  node_selector: {}
  extra_args:
    default-ssl-certificate: "ingress-nginx/ingress-default-cert"
cluster_name: ""
cloud_provider:
  name: ""
prefix_path: ""
addon_job_timeout: 0
bastion_host:
  address: ""
  port: ""
  user: ""
  ssh_key: ""
  ssh_key_path: ""
  ssh_cert: ""
  ssh_cert_path: ""
monitoring:
  provider: ""
  options: {}
restore:
  restore: false
  snapshot_name: ""
dns: null
